
@article{noauthor_iet_nodate,
	title = {{IET} {Information} {Security}},
	url = {https://digital-library.theiet.org/content/journals/iet-ifs},
	abstract = {IET Information Security publishes original research papers in the following areas of information security and cryptography. Submitting authors should specify clearly in their covering statement the area into which their paper falls.},
	language = {en},
	urldate = {2019-09-19},
	file = {Snapshot:/home/rodger/Zotero/storage/LLTVYGY7/iet-ifs.html:text/html}
}

@article{li_detection_2019,
	title = {Detection of double compression in {HEVC} videos based on {TU} size and quantised {DCT} coefficients},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2017.0555},
	abstract = {With the advent of sophisticated and low-cost video editing software, digital videos are highly vulnerable to be tampered. The authenticity and integrity identification of digital videos is an urgent issue. In this study, an effective method to detect double High Efficiency Video Coding (HEVC) video compression with different quantisation parameter (QP) is proposed, which often occurs in the video tampering process. First, the effects of QP on the distributions of Discrete Cosine Transform (DCT) coefficients and Transform Unit (TU) size are analysed. Then a feature set including 17 features is derived from quantised DCT coefficients and TU size. It can characterize the statistical differences between single and double compressed videos. Finally, the Library for Support Vector Machine classifier is exploited to identify whether a given HEVC video has been double compressed or not. Experimental results demonstrate that the authors’ detection method has a good comprehensive performance.},
	language = {English},
	number = {1},
	journal = {IET Information Security},
	author = {Li, Qian and Wang, Rangding and Xu, Dawen},
	month = jan,
	year = {2019},
	keywords = {authenticity, authors, different quantisation parameter, digital videos, double compressed videos, double compression, double High Efficiency Video Coding video compression, given HEVC video, HEVC videos, integrity identification, low-cost video editing software, QP, quantised DCT coefficients, single videos, TU size, video tampering process},
	pages = {1--6(5)},
	annote = {1m4s, trash, creating a new video standard isn't very interesting}
}

@article{chakraborty_towards_2019,
	title = {Towards incorporating honeywords in n-session recording attack resilient unaided authentication services},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2017.0538},
	abstract = {Unaided authentication services provide the flexibility to login without being dependent on any external hardware. n-Session recording attack resilient unaided authentication services (n-SRRUASs) are known for setting high security standards against different client side threats. However, because of their authentication procedure, the authors have identified that these services cope poorly with handling the server side issues. Though modern days’ research heavily depends on the honeywords (or fake passwords) as a countermeasure of server side threats, they have shown that the honeywords cannot be directly applied to n-SRRUAS. The authors’ analysis shows that the idea of incorporating the honeywords directly into an n-SRRUAS is particularly difficult as it prevents the system from storing passwords after applying password-based key derivation function or in the form of a hashed string. In this study, they have proposed few generic principles for incorporating the honeywords into n-SRRUAS and show that the proposed principles are sufficient for incorporating the honeywords into any n-SRRUAS. Furthermore, with the help of an existing n-SRRUAS, they have shown that the proposed idea is truly implementable in practice to fill the existing gap.},
	language = {English},
	number = {1},
	journal = {IET Information Security},
	author = {Chakraborty, Nilesh and Mondal, Samrat},
	month = jan,
	year = {2019},
	keywords = {authentication procedure, fake passwords, g password-based key derivation function, generic principles, hashed string, honeywords, n-session recording attack resilient unaided authentication services, n-SRRUAS, server side threats},
	pages = {7--18(11)},
	annote = {1m31s, trash, very specific application, don't think it's meaningful}
}

@article{musavi_hpcgnature:_2019,
	title = {{HPCgnature}: a hardware-based application-level intrusion detection system},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2017.0629},
	abstract = {In the past decade, commodity software applications have been deployed more than ever in almost every domain. Having the ability to differentiate the original trusted application at run-time from its compromised, mimic or trojanised versions would mitigate a broad range of intrusion threats to these applications. This has been addressed by application-level intrusion detection systems, however, such schemes mostly depend on the system software for either monitoring or modelling the application. This is while system software can itself get compromised by kernel-level rootkit attacks. In this study, the authors have proposed a new hardware-based app-IDS, which works independent of the system software of the target system. The proposed method, referred to as HPCgnature, includes a new abstraction corresponding to the repetitious functionalities of programs. Such functionalities generate a distinguishing sequence of periods, referred to in this study as the Operational Periodicity. The method uses monitoring scheme based on external access to the hardware performance counters of CPUs. Implementing a prototype, they have shown how HPCgnature can detect intrusions in 12 complex interactive desktop applications. Evaluation results indicate this model could differentiate applications with 98\% accuracy, and can detect even small run-time code injection attacks by an accuracy of \&gt;75\%},
	language = {English},
	number = {1},
	journal = {IET Information Security},
	author = {Musavi, Seyyedeh Atefeh and Hashemi, Mahmoud Reza},
	month = jan,
	year = {2019},
	keywords = {commodity software applications, complex interactive desktop applications, complex kernel-level rootkit attacks, hardware based application-level intrusion detection system, hardware performance counters, HPCgnature, Operational Periodicity, original trusted application, system software},
	pages = {19--26(7)},
	annote = {1m1s, trash, intrusion detection based on periodicity might be interesting, but not sure it's relevant}
}

@article{rivera_costly_2019,
	title = {Costly freeware: a systematic analysis of abuse in download portals},
	volume = {13},
	copyright = {This is an open access article published by the IET under the Creative Commons Attribution-NonCommercial-NoDerivs License (http://creativecommons.org/licenses/by-nc-nd/3.0/)},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2017.0585},
	abstract = {Freeware is proprietary software that can be used free of charge. A popular vector for distributing freeware is download portals, i.e. websites that index, categorise, and host programs. Download portals can be abused to distribute potentially unwanted programs (PUP) and malware. The abuse can be due to PUP and malware authors uploading their ware, by benign freeware authors joining as affiliate publishers of pay-per-install (PPI) services and other affiliate programs, or by malicious download portal owners. The authors perform a systematic study of abuse in download portals. They build a platform to crawl download portals and apply it to download 191 K Windows freeware installers from 20 download portals. They analyse the collected installers and execute them in a sandbox to monitor their installation. They measure an overall ratio of PUP and malware between 8\% (conservative estimate) and 26\% (lax estimate). In 18 of the 20 download portals examined the amount of PUP and malware is below 9\%. However, they also find two download portals exclusively used to distribute PPI downloaders. Finally, they detail different abusive behaviours that authors of undesirable programs use to distribute their programs through download portals.},
	language = {English},
	number = {1},
	journal = {IET Information Security},
	author = {Rivera, Richard and Kotzias, Platon and Sudhodanan, Avinash and Caballero, Juan},
	month = jan,
	year = {2019},
	keywords = {malicious download portal owners, pay-per-install services, potentially unwanted programs, PPI services, proprietary software, PUP, Windows freeware installers},
	pages = {27--35(8)},
	annote = {60s, trash, everyone knows download portals are full of malware}
}

@article{mihaljevic_security_2019,
	title = {Security evaluation and design elements for a class of randomised encryptions},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2017.0271},
	abstract = {This study considers a class of randomised encryption techniques, where the encrypted data suffers from noise through transmission over a communication channel. It focuses on the encoding–encryption framework, where the data is first encoded using error correction coding for reliability, then encrypted with a stream cipher. A dedicated homophonic encoder is added to enhance the protection of the stream cipher key, on which relies the security of all the system transmissions. This study presents a security evaluation of such systems in a chosen plaintext attack scenario, which shows that the computational complexity security is lower bounded by the related LPN (learning from parity with noise) complexity in both the average and worst cases. This gives guidelines to construct a dedicated homophonic encoder which maximises the complexity of the underlying LPN problem for a given encoding overhead. A generic homophonic coding strategy that fulfils the proposed design criteria is then given, which thus both enhances security while minimising the induced overhead. Finally, a comparison of encryption schemes based on the LPN problem with and without homophonic coding is considered.},
	language = {English},
	number = {1},
	journal = {IET Information Security},
	author = {Mihaljević, Miodrag J. and Oggier, Frédérique},
	month = jan,
	year = {2019},
	keywords = {average cases, chosen plaintext attack scenario, communication channel, computational complexity security, dedicated homophonic encoder, design criteria, design elements, encoded using error correction coding, encoding–encryption framework, encrypted data suffers, encryption schemes, enhances security, generic homophonic coding strategy, given encoding overhead, noise, randomised encryption techniques, randomised encryptions, related LPN, security evaluation, stream cipher key, system transmissions, underlying LPN problem, worst cases},
	pages = {36--47(11)},
	annote = {34s, trash, not interested in encryption}
}

@article{jia_network_2019,
	title = {Network intrusion detection algorithm based on deep neural network},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5258},
	abstract = {With the rapid development of network technology, active defending of the network intrusion is more important than before. In order to improve the intelligence and accuracy of network intrusion detection and reduce false alarms, a new deep neural network (NDNN) model based intrusion detection method is designed. A NDNN with four hidden layers is modelled to capture and classify the intrusion features of the KDD99 and NSL-KDD training data. Experiments on KDD99 and NSL-KDD dataset shows that the NDNN-based method improves the performance of the intrusion detection system (IDS) and the accuracy rate can be obtained as high as 99.9\%, which is higher when compared with other dozens of intrusion detection methods. This NDNN model can be applied in IDS to make the system more secure.},
	language = {English},
	number = {1},
	journal = {IET Information Security},
	author = {Jia, Yang and Wang, Meng and Wang, Yagang},
	month = jan,
	year = {2019},
	keywords = {deep neural network model, intrusion features, KDD99 training data, NDNN model, network intrusion detection algorithm, network technology, NSL-KDD dataset, NSL-KDD training data},
	pages = {48--53(5)},
	annote = {34s, scan, deep learning for intrusion detection is interesting
scan notes: This paper proposed a deep learning algorithm vs machine learning. It wasn't very significant as it showed similar detection rates {\textgreater}98\% as other algorithms.
 }
}

@article{barari_secure_2019,
	title = {Secure degrees of freedom of two-user {X}-channel with synergistic alternating channel state information at transmitters},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5239},
	abstract = {In this study, a two-user single-input single-output X-channel with confidential messages is addressed. In this model, the authors assume that the transmitters have access to synergistic alternating channel state information. During different time slots, the channel state information at transmitters (CSIT) alternate between three states including perfect CSIT, delayed CSIT, and no CSIT. By using the eminent synergistic benefits of the CSIT pattern, some schemes capable of attaining the maximum achievable secure degrees of freedom (SDoF) are presented. Additionally, in devising the schemes, the minimal CSIT patterns required to achieve optimal SDoF are introduced. It is shown that for CSIT patterns which are weaker than minimal ones, using a half-duplex relay can assist the network in obtaining the optimal SDoF. Indeed, the relay alleviates the effects of the lack of knowledge at transmitters on achievable SDoF.},
	language = {English},
	number = {1},
	journal = {IET Information Security},
	author = {Barari, Bardiya and Sangdeh, Pedram Kheirkhah and Akhbari, Bahareh},
	month = jan,
	year = {2019},
	keywords = {CSIT pattern, delayed CSIT, eminent synergistic benefits, half-duplex relay, maximum achievable secure degrees, minimal CSIT patterns, perfect CSIT, secure degrees of freedom, synergistic alternating channel state information, transmitters, two-user single-input single-output X-channel, two-user X-channel},
	pages = {54--60(6)},
	annote = {1m27s, trash, poorly written}
}

@article{guo_privacy_2019,
	title = {Privacy preserving weighted similarity search scheme for encrypted data},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5187},
	abstract = {Cloud computing has become increasingly popular among individuals and enterprises because of the benefits it provides by outsourcing their data to cloud servers. However, the security of the outsourced data has become a major concern. For privacy concerns, searchable encryption, which supports searching over encrypted data, has been proposed and developed rapidly in secure Boolean search and similarity search. However, different users may have different requirements on their queries, which mean different weighted searches. This problem can be solved perfectly in the plaintext domain, but hard to be addressed over encrypted data. In this study, the authors use locality-sensitive hashing (LSH) and searchable symmetric encryption (SSE) to deal with a privacy preserving weighted similarity search. In the authors’ scheme, data users can generate a search request and set the weight for each attribute according to their requirements. They treat the LSH values as keywords and mix them into the framework of SSE. They use homomorphic encryption to securely address the weight problem and return the top-k data without revealing any weight information of data users. They formally analysed the security strength of their scheme. Extensive experiments on actual datasets showed that their scheme is extremely effective and efficient.},
	language = {English},
	number = {1},
	journal = {IET Information Security},
	author = {Guo, Cheng and Tian, Pengxu and Chang, Chin-Chen},
	month = jan,
	year = {2019},
	keywords = {cloud computing, data users, different requirements, different users, different weighted searches, encrypted data, homomorphic encryption, outsourced data, privacy concerns, search request, searchable encryption, searchable symmetric encryption, weight information, weight problem, weighted similarity search scheme},
	pages = {61--69(8)},
	annote = {48s, trash, not interested in encryption}
}

@article{li_meet---middle_2019,
	title = {Meet-in-the-middle attacks on round-reduced tweakable block cipher {Deoxys}-{BC}},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5091},
	abstract = {Deoxys-BC is a tweakable block cipher designed by Jean et al. at ASIACRYPT 2014 within the TWEAKEY framework. Then Deoxys-BC is used in the CAESAR finalist Deoxys. In this study, the authors consider the security of Deoxys-BC against meet-in-the-middle attack in the single-key setting. Using the idea that a chosen tweak difference allows to cancel a difference in the state, they can construct 5-round meet-in-the-middle distinguisher on Deoxys-BC-128-128 which can be extended to attack on 8-round Deoxys-BC-128-128. Moreover, they construct 6-round meet-in-the-middle distinguisher on Deoxys-BC-256-128 which can be extended to attack on 10-round Deoxys-BC-256-128. As far as the authors know, these are the best attacks against Deoxys-BC in the single-key setting.},
	language = {English},
	number = {1},
	journal = {IET Information Security},
	author = {Li, Rongjia and Jin, Chenhui},
	month = jan,
	year = {2019},
	keywords = {Deoxys-BC-128-128, Deoxys-BC-256-128, meet-in-the-middle attack, meet-in-the-middle distinguisher, round-reduced tweakable block cipher Deoxys-BC},
	pages = {70--75(5)},
	annote = {30s, trash, not interested in encryption}
}

@article{lee_dynamic_2019,
	title = {Dynamic reencryption of return addresses},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5142},
	abstract = {The authors present dynamic reencryption of return addresses to mitigate their leakage. The authors’ method enforces programs to save return addresses as encrypted and renew the encryption states with fresh keys before or after vulnerable operations. When a function returns, it should restore the return address from its encryption using the most recent key not to cause a crash. Under the protection of their method, return addresses and keys may leak, but the disclosed bits become garbage because keys govern all return addresses through encryption, while changing before control-flow proceeds into a vulnerable region. As a result, it becomes probabilistically infeasible to build exploits for intercepting control-flow by using leaked return addresses or keys. They implemented the proposed method as an extension of the LLVM compiler that inserts reencryption code where necessary. They also have confirmed its effectiveness against information leak attacks carried out in the early stage of blind return-oriented programming (BROP). The performance overhead ranges below 11.6\% for processor-intensive programs and 4.12\% or less for web servers.},
	language = {English},
	number = {1},
	journal = {IET Information Security},
	author = {Lee, Hyungyu and Pyo, Changwoo and Lee, Gyungho},
	month = jan,
	year = {2019},
	keywords = {dynamic reencryption, function returns, leaked return addresses, return address},
	pages = {76--85(9)},
	annote = {1m2s, trash, encrypted return values seems to costly to be practical}
}

@article{zhang_division_2019,
	title = {Division cryptanalysis of block ciphers with a binary diffusion layer},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5151},
	abstract = {In this study, the authors propose an accurate approach to model the propagation of the division property of linear layers by the smallest amount of inequalities. The solutions of the inequalities are exactly the division trails of a linear transformation. Therefore, the description is compact and optimal. As applications of their results, they present a 7-round integral distinguisher for both Midori64 and Midori128. The designers of Midori only obtained a 3.5-round integral characteristic. For Skinny64, they find a 10-round integral distinguisher which was previously found by the designers. It is well to remind that their result proves that 7 rounds and 10 rounds are the upper bounds of Midori and Skinny64 correspondingly when searching for integral distinguishers based on division property. The significance of their result lies in that they shed light on how far division cryptanalysis can influence the security analysis of block ciphers with a binary diffusion layer, and their technique can be used to prove security against division cryptanalysis.},
	language = {English},
	number = {2},
	journal = {IET Information Security},
	author = {Zhang, Wenying and Rijmen, Vincent},
	month = mar,
	year = {2019},
	keywords = {10-round integral distinguisher, 3.5-round integral characteristic, 7-round integral distinguisher, binary diffusion layer, block ciphers, division cryptanalysis, linear layers division property, linear transformation division trails, Midori128, Midori64, security analysis, Skinny64},
	pages = {87--95(8)},
	annote = {3s, trash, not interested in encryption}
}

@article{jha_security_2019,
	title = {Security analysis of {ABAC} under an administrative model},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5010},
	abstract = {In the present-day computing environment, where access control decisions are often dependent on contextual information like the location of the requesting user and the time of access request, attribute-based access control (ABAC) has emerged as a suitable choice for expressing security policies. In an ABAC system, access decisions depend on the set of attribute values associated with the subjects, resources, and the environment in which an access request is made. In such systems, the task of managing the set of attributes associated with the entities as well as that of analysing and understanding the security implications of each attribute assignment is of paramount importance. Here, the authors first introduce a comprehensive attribute-based administrative model, named as AMABAC (Administrative Model for ABAC), for ABAC systems and then suggest a methodology for analysing the security properties of ABAC in the presence of the administrative model. For performing analysis, the authors use μZ, a satisfiability modulo theories-based model checking tool. The authors study the impact of the various components of ABAC and AMABAC on the time taken for security analysis.},
	language = {English},
	number = {2},
	journal = {IET Information Security},
	author = {Jha, Sadhana and Sural, Shamik and Atluri, Vijayalakshmi and Vaidya, Jaideep},
	month = mar,
	year = {2019},
	keywords = {ABAC system, access control decisions, access decisions, access request, attribute assignment, attribute values, attribute-based access control, comprehensive attribute-based administrative model, contextual information, present-day computing environment, requesting user, satisfiability modulo theories-based model checking tool, security analysis, security implications, security policies, security properties},
	pages = {96--103(7)},
	annote = {44s, trash, attribute based decision making not relevant to me}
}

@article{qin_quantum_2019,
	title = {Quantum secret sharing by using {Fourier} transform on orbital angular momentum},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5149},
	abstract = {A quantum secret sharing scheme based on orbital angular momentum (OAM) is proposed. The dealer generates single particles in OAM basis or angular position (ANG) basis randomly. The participants encode their private keys into the particles through performing quantum Fourier transforms. Then the dealer can use the single-particle measurements to get the shared secret. In the authors’ scheme, the secret is protected by the distinguishability of OAM basis and ANG basis. Compared to the traditional two-dimensional schemes, the authors’ scheme can use the higher dimension of OAM to increase the detecting rate of eavesdropping, and enhance the security in practice. Besides, only the single particles are needed in their scheme. Compared to the schemes based on entangled particles, the authors’ scheme will be more practical with the present technology.},
	language = {English},
	number = {2},
	journal = {IET Information Security},
	author = {Qin, Huawang and Tso, Raylin and Dai, Yuewei},
	month = mar,
	year = {2019},
	keywords = {ANG basis, angular position, entangled particles, OAM basis, orbital angular momentum, private key encoding, quantum Fourier transform, quantum secret sharing scheme, security enhancement, single-particle measurements, two-dimensional schemes},
	pages = {104--108(4)},
	annote = {55s, trash, just nonsense word salad}
}

@article{han_detecting_2019,
	title = {Detecting anomalous traffic in the controlled network based on cross entropy and support vector machine},
	volume = {13},
	copyright = {This is an open access article published by the IET under the Creative Commons Attribution License (http://creativecommons.org/licenses/by/3.0/)},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5186},
	abstract = {Network anomaly detection is an effective way for analysing and detecting malicious attacks. However, the typical anomaly detection techniques cannot perform the desired effect in the controlled network just as in the general network. In the circumstance of the controlled network, the detection performance will be lowered due to its special characteristics including the stronger regularity, higher dimensionality and subtler fluctuation of its traffic. On the motivation, the study proposes a novel classifier framework based on cross entropy and support vector machine (SVM). The technique first subtracts the representative traffic characteristics from the network traffic and defines a 7-tuple feature vector for the controlled network by extending the traditional 5-tuple representation of the usual network. Then the probability distributions and cross entropies of the 7 tuples are calculated during the defined statistical window so as to generate the 7-tuple cross-entropy feature vector for profiling the network traffic fluctuation in the controlled network. Finally, the multi-class SVM classifier is trained by importing the 7-tuple cross-entropy feature vectors. Experimental results show that the proposed classifier can achieve higher detection rates and is more suitable to be used in the controlled network than the typical detection techniques.},
	language = {English},
	number = {2},
	journal = {IET Information Security},
	author = {Han, Weijie and Xue, Jingfeng and Yan, Hui},
	month = mar,
	year = {2019},
	keywords = {5-tuple representation, 7-tuple cross-entropy feature vector, anomalous traffic detection, controlled network, malicious attacks detection, network anomaly detection, network traffic fluctuation, probability distributions, statistical window, support vector machine, SVM classifier, traffic characteristics},
	pages = {109--116(7)},
	annote = {47s, trash, variation on a theme of network detection, not cutting edge}
}

@article{wei_new_2019,
	title = {New second-order threshold implementation of {AES}},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5244},
	abstract = {In this work, the authors propose some alternative hardware efficient masking schemes dedicated to protect the Advanced Encryption Standard (AES) against higher order differential power analysis (DPA). In general, the existing masking schemes all have in common an intrinsic trade-off between the two main parameters of interest, namely the generation of fresh random masking values and the cost of hardware implementation. The design of efficient masking schemes which are non-expensive in both aspects appears to be a difficult task. In this study, the authors propose a second-order threshold implementation of AES, which is characterised by a beneficial trade-off between the two parameters. More precisely, compared to the masking scheme of De Cnudde et al. at CHES 2016, which currently attains the best practical trade-off, the proposed masking scheme requires 28.4\% less random masking bits, whereas the implementation cost is slightly increased for about 13.7\% (thus the chip area is 1.4 kGE larger). This masking scheme has been used to implement AES on an field-programmable gate array (FPGA) platform and its resistance against the second-order DPA in a simulated attack environment has been confirmed.},
	language = {English},
	number = {2},
	journal = {IET Information Security},
	author = {Wei, Yongzhuang and Yao, Fu and Pasalic, Enes and Wang, An},
	month = mar,
	year = {2019},
	keywords = {Advanced Encryption Standard, alternative hardware efficient masking schemes, FPGA platform, hardware implementation, higher order differential power analysis, masking scheme, second-order differential power analysis},
	pages = {117--124(7)},
	annote = {17s, trash, no encryption}
}

@article{zheng_extension_2019,
	title = {On the extension and security of key schedule of {GOST}},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5291},
	abstract = {A type of simple key schedule especially suitable for lightweight block ciphers is defined as straightforward key schedule in this study. As a typical example, GOST-type key schedule, which is an extension of the key schedules of Russian Standard GOST and its newly modified version GOST2, is introduced and classified. GOST2 is designed based on the GOST encryption structure with different but the same type of key schedule to overcome the weakness of GOST against self-similarity properties-based attacks. However, it has been shown in Fast Software Encryption 2017, the simple change in the key schedule is insufficient to offer 256-bit security. By constructing an evaluation framework combining self-similarity properties and meet-in-the-middle attack, properties of GOST-type key schedules are evaluated, and candidate key schedules are provided in this work. These candidate key schedules are able to provide much better security for GOST and GOST2 ciphers than their original key schedules, and the pre-existing self-similarity properties-based attacks of full round GOST and GOST2 can be avoided. The designers of GOST and GOST2 should have been more cautious choosing the parameters of key schedules. The evaluation framework proposed can be used for reference in the design of other Feistel ciphers with straightforward key schedules.},
	language = {English},
	number = {2},
	journal = {IET Information Security},
	author = {Zheng, Yafei and Wu, Wenling},
	month = mar,
	year = {2019},
	keywords = {Fast Software Encryption 2017, GOST encryption structure, GOST-type key schedule, GOST2 ciphers, lightweight block ciphers, meet-in-the-middle attack, Russian Standard GOST, self-similarity properties-based attacks},
	pages = {125--132(7)},
	annote = {12s, trash, no encryption}
}

@article{bhadane_detecting_2019,
	title = {Detecting lateral spear phishing attacks in organisations},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5090},
	abstract = {Lateral spear phishing attack is a powerful type of social engineering attack carried out using compromised email account(s) within the target organisation. Spear phishing attacks are difficult to detect due to the nature of these attacks. The inclusion of a lateral attack vector makes detection more challenging. The authors present an approach to detect lateral spear phishing attacks in organisations in real-time. Their approach uses features derived from domain knowledge and analysis of characteristics pertaining to such attacks, combined with their scoring technique which works on non-labelled dataset. They evaluate the approach on several years’ worth of real-world email dataset collected from volunteers in their institute. They were able to achieve false positive rate of below 1\%, and also detected two instances of compromised accounts which were not known earlier. A comparison of their scoring technique with machine learning based anomaly detection techniques shows the proposed technique to be more suited for practical use. The proposed approach is primarily aimed at complementing existing detection techniques on email servers. However, they also developed a Chrome browser extension to demonstrate that such a system can also be used independently by organisations within their network.},
	language = {English},
	number = {2},
	journal = {IET Information Security},
	author = {Bhadane, Aniket and Mane, Sunil B.},
	month = mar,
	year = {2019},
	keywords = {anomaly detection techniques, Chrome browser extension, lateral attack vector, lateral spear phishing attack detection, machine learning, organisations, social engineering attack},
	pages = {133--140(7)},
	annote = {1m28s, scan, detecting later spearfishing seems like a relevant problem
scan notes: Spear fishing relies on reporting, detecting internal spear fishing and scoring relevance is new and helpful.}
}

@article{li_advanced_2019,
	title = {Advanced conditional differential attack on {Grain}-like stream cipher and application on {Grain} v1},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5180},
	abstract = {Conditional differential attacks against non-linear feedback shift register based cryptosystems were proposed by Knellwolf et al. at Asiacrypt 2010. In this study, the authors propose an advanced conditional differential attack on Grain-like stream cipher. They trace propagations of a single bit difference of internal states both inversely and forward. Methods of both searching for the longest inverse difference characteristic with probability one and deriving initial value (IV) conditions with the max inverse round are introduced. When tracing forward, conditions are imposed to limit the propagation of difference to obtain a high bias. Conditions of the proposed method are only imposed on IV bits and the proposed attack works in the single-key setting. Moreover, a method of recovering key expressions as well as bias-complexity-success probability target is presented in this study. Using the proposed method, the authors conduct a key recovery attack on 114-round Grain v1, recovering 6 key expressions with the time complexity of 232, which is also verified by experiments. With more conditions imposed, this attack can be improved to Grain v1 of 120 rounds, recovering 12 key expressions with the time complexity of 242.75 and theoretical success probability of about 93\%, which is ten rounds longer than the longest previous result of Grain v1 in the single-key setting.},
	language = {English},
	number = {2},
	journal = {IET Information Security},
	author = {Li, Jun-Zhi and Guan, Jie},
	month = mar,
	year = {2019},
	keywords = {12 key expressions, 6 key expressions, advanced conditional differential attack, bias-complexity-success probability target, conditional differential attacks, Grain-like stream cipher, initial value conditions, key recovery attack, longest inverse difference, max inverse round, nonlinear feedback shift register based cryptosystems, single bit difference, single-key setting, trace propagations},
	pages = {141--148(7)},
	annote = {26s, trash, too narrow focus, attacks on a specific stream cypher}
}

@article{rongrong_framework_2019,
	title = {Framework for risk assessment in cyber situational awareness},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5189},
	abstract = {A large number of data is generated to help network analysts to evaluate the network security situation in traditional detection and prevention measures, but it is not used fully and effectively, there is not a holistic view of the network situation on it for now. To address this issue, a framework is proposed to evaluate the security situation of the network from three dimensions: threat, vulnerability and stability, and merge the results at decision level to measure the security situation of the overall network. In the case studies, the authors demonstrate how the framework is deployed in the network and how to use it to reflect the security situation of the network in real time. Results of the case study show that the framework can evaluate the security situation of the network accurately and reasonably.},
	language = {English},
	number = {2},
	journal = {IET Information Security},
	author = {Rongrong, Xi and Xiaochun, Yun and Zhiyu, Hao},
	month = mar,
	year = {2019},
	keywords = {cyber situational awareness, network analysts, network security situation, network situation, prevention measures, risk assessment, traditional detection},
	pages = {149--156(7)},
	annote = {31s, trash, this was a maybe, data analysis on network traffic}
}

@article{shen_provably_2019,
	title = {Provably secure certificateless aggregate signature scheme with designated verifier in an improved security model},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5226},
	abstract = {An aggregate signature (AS) scheme combines multiple signatures which is generated by many different users into a single one. This feature is very beneficial for diminishing storage cost, bandwidth and verification cost. Many previous attempts have been made for designing AS schemes, while the former security models have not clearly addressed coalition attacks, and most of the existing AS schemes cannot resist these kinds of attacks. In this study, the authors provide a modified security model of certificateless AS (CLAS) schemes and then give a new CLAS scheme. The security of their present scheme can be rigorously proved based on the computational Diffie–Hellman assumption in the random oracle model. Furthermore, their scheme can resist such coalition attacks, i.e. an AS in their scheme is valid iff all single signatures used to generate the AS are valid.},
	language = {English},
	number = {3},
	journal = {IET Information Security},
	author = {Shen, Limin and Ma, Jianfeng and Miao, Yinbin and Liu, Hai},
	month = may,
	year = {2019},
	keywords = {certificateless aggregate signature scheme, CLAS scheme, coalition attacks, computational Diffie-Hellman assumption, random oracle model, security models, verification cost},
	pages = {167--173(6)},
	annote = {42s, trash, certificate scheme, too close to encyrption}
}

@article{zhang_unsupervised_2019,
	title = {Unsupervised approach for detecting shilling attacks in collaborative recommender systems based on user rating behaviours},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5131},
	abstract = {Collaborative recommender systems have been known to be extremely vulnerable to shilling attacks. To prevent such attacks, many detection approaches including supervised and unsupervised have been proposed. However, the supervised approaches are only suitable for detecting known types of attacks and the unsupervised approaches require a priori knowledge to ensure the detection performance. To address the limitations, the authors propose an unsupervised approach for detecting shilling attacks based on user rating behaviours. They first use Gibbs latent Dirichlet allocation model to extract latent topics of user preferences from user rating item sequences, then they use mixture transition distribution model to construct the user\&apos;s preference model and present several metrics to capture the diversity between genuine and attack users in rating behaviours. In the case of unknown attack size, the number of attack users is obtained by analysing the critical point of rating behaviour suspicious degrees between genuine and attack users, and based on which the attack users are identified. The experimental results on the MovieLens 1 M dataset show that the proposed approach outperforms the baseline methods in terms of recall and precision metrics.},
	language = {English},
	number = {3},
	journal = {IET Information Security},
	author = {Zhang, Fuzhi and Ling, Zhoujun and Wang, Shilei},
	month = may,
	year = {2019},
	keywords = {collaborative recommender systems, detection performance, Gibbs latent Dirichlet allocation model, latent topic extraction, shilling attacks detection, unsupervised approach, use Gibbs latent Dirichlet allocation model, user preferences, user rating item sequences},
	pages = {174--187(13)},
	annote = {51s, trash, not relevant to me}
}

@article{sree_hap:_2019,
	title = {{HAP}: detection of {HTTP} flooding attacks in cloud using diffusion map and affinity propagation clustering},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5382},
	abstract = {The extreme growth of Internet resources leads to several kinds of attacks. Cybercrime is one of the dominant threats apart from data defence mechanism, which enhances the economy, resource management, and service quality. Among them, HTTP flooding attacks in the cloud are one of the most prevalent threats as it depletes the cloud resources and services. It is difficult to distinguish the anomalous traffic by extracting the actual payload since most of the payload could not be accessed as they are encrypted and varies dynamically based on the user input. Hence, the proposed method uses web server logs that can be easily accessed to detect the attacks. This study highlights the detection methods by extracting the features from the web server logs and also deals with the reduction in the dimensionality of the features using diffusion map. The anomalies are detected by affinity propagation clustering technique and also by monitoring the status of the virtual machine. Furthermore, the Dempster–Shafer theory focuses on the identification of the suspicious user. It is inferred from the experimental results that the proposed method enhances the detection performance with very few false alarms than existing methods.},
	language = {English},
	number = {3},
	journal = {IET Information Security},
	author = {Sree, Thankaraja Raja and Bhanu, Somasundaram Mary Saira},
	month = may,
	year = {2019},
	keywords = {actual payload, affinity propagation clustering technique, cloud resources, data defence mechanism, detection methods, detection performance, diffusion map, dominant threats, extreme growth, HTTP flooding attacks, Internet resources, prevalent threats, resource management, service quality, services, web server logs},
	pages = {188--200(12)},
	annote = {40s, trash, web server logs to detect attacks? that's what they are for, not very innovative}
}

@article{soltani_event_2019,
	title = {Event reconstruction using temporal pattern of file system modification},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5209},
	abstract = {Nowadays, several digital forensic tools extract a lot of low-level information from different parts of the system. Constructing high-level information from low-level ones is very challenging. This study reconstructs high-level events by using the traces of applications that are found in the file system metadata. In this regard, an event reconstruction framework is proposed that determines which applications have been run on a compromised system. The proposed framework works in two phases. In the training phase, the signatures of various applications are constructed. The signature of an application is the temporal pattern of file system modification of the application. In the detection phase, at first, the temporal pattern of file system modification of the hard disk (TPFSM-D) of the compromised system is constructed. Then in order to determine whether a particular application has been run on the compromised system, the distance between the signature of the application and the TPFSM-D of the hard disk is calculated by using a proposed distance measure. Finally, a decision engine decides whether the application has been run on the compromised system. The proposed event reconstruction framework has been tested on different scenarios. The empirical results suggest that the framework is effective in reconstructing events.},
	language = {English},
	number = {3},
	journal = {IET Information Security},
	author = {Soltani, Somayeh and Seno, Seyed Amin Hosseini and Yazdi, Hadi Sadoghi},
	month = may,
	year = {2019},
	keywords = {event reconstruction framework, file system metadata, high-level events, high-level information, low-level information, temporal pattern of file system modification of the hard disk, TPFSM-D},
	pages = {201--212(11)},
	annote = {1m21s, trash, difficult to tell what this paper is even trying to do}
}

@article{abdelmalek_security_2019,
	title = {Security and fault tolerance evaluation of {TMR}–{QDI} circuits},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5439},
	abstract = {The authors report the results of a study on the impact of resistive bridging faults on triple modular redundancy (TMR)-based quasi-delay-insensitive (QDI) asynchronous countermeasures, which is used to provide a secure circuit against power analyses. They have carried out the present study on CADENCE using a resistive bridges fault model. They show that the resistive bridge faults can have serious impacts on the security of integrated circuits and it is possible to discover the secret data. Based on the bridges resistance value, there are three operating intervals of secure circuits, in which TMR-based QDI may or may not function correctly in the presence of two resistive bridge faults depending on the interval of the resistance value.},
	language = {English},
	number = {3},
	journal = {IET Information Security},
	author = {Abdelmalek, Ghania Ait and Ziani, Rezki and Mokdad, Rabah},
	month = may,
	year = {2019},
	keywords = {bridges resistance value, CADENCE, fault tolerance evaluation, integrated circuit security, integrated circuits, power analysis, resistive bridge fault model, secret data, secure circuit, TMR-based QDI, TMR–QDI circuits, triple modular redundancy-based quasidelay-insensitive asynchronous countermeasures},
	pages = {213--222(9)},
	annote = {50s, trash, poorly written, weak concept}
}

@article{sohail_multi-hop_2019,
	title = {Multi-hop interpersonal trust assessment in vehicular \textit{ad-hoc} networks using three-valued subjective logic},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5336},
	abstract = {Future vehicular networks need multi-hop trusted information among car manoeuvres as a solution to the persistent problem of road safety, and news sharing. However, malicious users in vehicular networks can also disseminate fake information among each other. Traditional public key infrastructure is not an efficient solution for recognising these malicious users, as they all have authorised entities. To cope with this problem, this study highlights novel idea, i.e. three-valued subjective logic (3VSL) as a trust model for multi-hop trust assessment among users in vehicular ad-hoc network (VANET). Trust among vehicle users is represented in the form of opinion derived from 3VSL and updated frequently due to vehicles random movement on the road. To support the authors’ proposed scheme, this study contains two parts in simulation, i.e. numerical and experimental analyses. Numerical analysis shows that 3VSL gives accurate trust assessment even with a bridge or random network topology, which is ignored previously by edge splitting. In the experimental part, we extend widely accepted ad-hoc on-demand distance vector routing protocol by directly applying trust fields to the routing table. The simulation experiment shows that their scheme achieves better performance in term of throughput and latencies in low mobility VANET scenario.},
	language = {English},
	number = {3},
	journal = {IET Information Security},
	author = {Sohail, Muhammad and Wang, Liangmin and Jiang, Shunrong and Zaineldeen, Samar and Ashraf, Rana Umair},
	month = may,
	year = {2019},
	keywords = {3VSL, ad-hoc on-demand distance vector routing protocol, car manoeuvres, future vehicular networks, malicious users, multihop interpersonal trust assessment, multihop trust assessment, multihop trusted information, news sharing, random network topology, road safety, three-valued subjective logic, traditional public key infrastructure, trust assessment, trust fields, trust model, vehicle users, vehicles random movement, vehicular ad-hoc network},
	pages = {223--230(7)},
	annote = {55s, keep, interesting take on ad-hoc vehicle network},
	annote = {scan: Proposing a trust/verification method for ad-hoc vehicle networks. Makes out of date assumptions about how the system design will work. Don't expect this to be relevant}
}

@article{parihar_fast_2019,
	title = {Fast {Montgomery} modular multiplier for {Rivest}–{Shamir}–{Adleman} cryptosystem},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5191},
	abstract = {A high-speed Montgomery modular multiplier is proposed in this study. This multiplier requires binary input and also generates a modular product in binary form. To speed up the process of multiplication, intermediate operands of the multiplier are kept in carry-save form. This multiplier employs a two-level carry-save adder architecture to keep intermediate operands in carry-save form. This multiplier also employs a look-ahead carry unit (LCU) for conversion of the final output from carry-save form to binary form. LCU is also utilised for pre-computation of intermediate operands. Format conversion and pre-computation require additional clock cycles. In general, each cycle of the Montgomery multipliers involves addition and shift operation followed by computation of the following quotient. The proposed multiplier adds and shifts as well as computes the following two quotients simultaneously to minimise the critical path delay. In addition, the proposed multiplier combines two iterations, which require additional intermediate operands. In this way, the execution time and the number of clock cycles required for multiplication are minimised significantly and extra clock cycles required for format conversion and operand pre-computation can be overlooked. Experimental results show that the proposed approach can achieve significant speed and throughput improvement as compared to previous multipliers.},
	language = {English},
	number = {3},
	journal = {IET Information Security},
	author = {Parihar, Aashish and Nakhate, Sangeeta},
	month = may,
	year = {2019},
	keywords = {binary form, binary input, clock cycles, critical path delay minimisation, fast Montgomery modular multiplier, format conversion, high-speed Montgomery modular multiplier, intermediate operands, modular product, operand precomputation, Rivest–Shamir–Adleman cryptosystem, two-level carry-save adder architecture},
	pages = {231--238(7)},
	annote = {37s, trash, not interested in crypto}
}

@article{uriarte_impact_2019,
	title = {Impact assessment of policy expressiveness of an optimised access control model for smart sensors},
	volume = {13},
	copyright = {This is an open access article published by the IET under the Creative Commons Attribution-NonCommercial-NoDerivs License (http://creativecommons.org/licenses/by-nc-nd/3.0/)},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5204},
	abstract = {In the incoming internet of things (IoT) applications, smart sensors expose services to interact with them, to be parameterised, managed and maintained. Therefore, fine-grained end-to-end access control enforcement is mandatory to tackle the derived security requirements. However, it is still not feasible in very constrained devices. There is an innovative access control model that conveys an expressive policy language and an optimised codification for tight and flexible access control enforcement in very constrained devices. Such tightness enabled by the expressiveness of the policy language leads to detailed policy instances that might impact on the performance and therefore, in the feasibility and further applicability. In this context, this study assesses how the policy length impacts the performance of the establishment of a security association through the protocol named Hidra proposed by such an adapted access control model. Consequently, the notable results of the performance evaluation prove the feasibility and adequacy of this access control model for the new smart IoT scenarios.},
	language = {English},
	number = {3},
	journal = {IET Information Security},
	author = {Uriarte, Mikel and Astorga, Jasone and Jacob, Eduardo and Huarte, Maider and López, Oscar},
	month = may,
	year = {2019},
	keywords = {constrained devices, derived security requirements, expressive policy language, fine-grained end-to-end access control enforcement, flexible access control enforcement, Hidra protocol, Internet of Things applications, optimised codification, optimised innovative access control model, smart IoT scenarios, smart sensors, tight access control enforcement},
	pages = {239--248(9)},
	annote = {1m11s, trash, new access control model for IoT}
}

@article{unlu_base_2019,
	title = {Base for algebraic cryptanalysis based on combined representation of {S}-box},
	volume = {13},
	copyright = {This is an open access article published by the IET under the Creative Commons Attribution -NonCommercial License (http://creativecommons.org/licenses/by-nc/3.0/)},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5051},
	abstract = {This study reveals an organised algebraic view on the Advanced Encryption Standard (AES), and in particular the S-box. A clear visualisation of algebraic expressions is granted for both the cipher part and the key schedule part of AES. Additionally, by introducing the combined representation of the S-box, alternative methods can be constructed to serve algebraic cryptanalysis on AES. The process to obtain a combined representation of the S-box, as a combination of four bits, the input value\&apos;s multiplicative inverse and bytes in hexadecimal notion, may be of high importance for other proposed ciphers too built with layers of S-boxes.},
	language = {English},
	number = {3},
	journal = {IET Information Security},
	author = {Unlu, Bekir},
	month = may,
	year = {2019},
	keywords = {advanced encryption standard, AES, algebraic cryptanalysis, algebraic expressions, cipher part, clear visualisation, S-boxes},
	pages = {249--257(8)},
	annote = {10s, trash, not interested in cryptography}
}

@article{zhang_re-definable_2019,
	title = {Re-definable access control over outsourced data in cloud storage systems},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5365},
	abstract = {There is an increasing concern for data privacy when people outsource their data to remote cloud storage servers. To secure outsourced data, cloud users are suggested to employ cryptographic encryption to specify access policies such that only users meeting the policies can access the data. After the application of an encryption, however, users are difficult to modify their access policies since the policies were already formulated by the encryption. To address such problem, the authors propose a new approach referred to as re-definable access control (RDAC). The RDAC utilises identity-based encryption (IBE) and attribute-based encryption (ABE) to secure outsourced data and allows users to choose either to achieve access control according to their capability and requirements. Moreover, the RDAC allows users to change simple access policies into fine-grained access policies by converting IBE encrypted files into ABE encrypted ones, without leaking the underlying data. Surprisingly, the access policy conversion does not require the users to perform any costly computation, nor the storage servers to be disturbed. The authors prove the security of RDAC under a rigorous definition, and empirically show that the introduction of the conversion incurs almost no costs to the outsourcing and access procedures.},
	language = {English},
	number = {3},
	journal = {IET Information Security},
	author = {Zhang, Zhigang and Chang, Chaowen and Guo, Zhimin and Han, Peisheng},
	month = may,
	year = {2019},
	keywords = {ABE encrypted ones, access policy conversion, access procedures, cloud storage systems, cloud users, cryptographic encryption, data privacy, fine-grained access policies, outsourced data, outsourcing, RDAC utilises identity-based encryption, re-definable access control, remote cloud storage servers, simple access policies, underlying data},
	pages = {258--268(10)},
	annote = {1m20s, scan, cloud storage security/privacy very relevant for the future},
	annote = {scan: Secure cloud storage is a relevant problem. Propose interesting idea to convert data encrypted with identity based encryption to attribute based encryption so users with correct attributes could share/read data.}
}

@article{aysan_analysis_2019,
	title = {Analysis of dynamic code updating in {Android} with security perspective},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5316},
	abstract = {Attackers have been searching for security vulnerabilities to exploit in Android applications. Such security vulnerabilities include Android applications that could load code at runtime which helps attackers avoid detection by static analysis tools. In this study, an extensive analysis is conducted in order to see how attackers employ updating techniques to exploit such vulnerabilities and to assess the security risks of applications in the marketplace using these techniques. A comprehensive analysis was carried out on nearly 30,000 applications collected from three different Android markets and two malware datasets. Static, dynamic and permission-based analyses were employed in order to monitor malicious activities in such applications, and new malicious applications using updating techniques were discovered in Google Play. The results show that applications employing code updating techniques are on the rise. It is believed that this is the first study of its kind to monitor updating behaviours of applications during their execution. This analysis allows us to deeply analyse suspicious applications and thereby develop better security solutions.},
	language = {English},
	number = {3},
	journal = {IET Information Security},
	author = {Aysan, Ahmet I. and Sakiz, Fatih and Sen, Sevil},
	month = may,
	year = {2019},
	keywords = {Android applications, code updating techniques, Google Play, malicious applications, malware datasets, permission-based analyses, security vulnerabilities, static analysis tools},
	pages = {269--277(8)},
	annote = {1m 11s, scan, interesting analysis of dynamic loading malware}
}

@article{sheikhi-garjan_threshold_2019,
	title = {Threshold verifiable multi-secret sharing based on elliptic curves and {Chinese} remainder theorem},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5174},
	abstract = {In this study, the authors propose a new protocol to share secret shadows for verifiable ( t , n ) secret sharing (VSS) schemes. Unlike traditional VSS schemes, whose communications between the dealer and the participants require a secure channel, the authors’ new scheme relies on the elliptic curve cryptosystem and the Chinese remainder theorem operates over a public channel. The security of the secret shadows and the verification algorithm are based on the hardness of the elliptic curve discrete logarithm problem. They also extend the proposed scheme to an efficient verifiable multi-secret sharing (VMSS) scheme, particularly when the number of secrets is more than the threshold. As a result, their scheme is a multi-use and efficient VMSS on the public channel which provides the same level of security as traditional VMSS schemes with much shorter keys.},
	language = {English},
	number = {3},
	journal = {IET Information Security},
	author = {Sheikhi-Garjan, Maryam and Bahramian, Mojtaba and Doche, Christophe},
	month = may,
	year = {2019},
	keywords = {Chinese remainder theorem, efficient verifiable multisecret sharing, elliptic curve cryptosystem, elliptic curve discrete logarithm problem, elliptic curves, public channel, secret shadows, secure channel, threshold verifiable multisecret sharing, traditional VMSS schemes, traditional VSS schemes},
	pages = {278--284(6)},
	annote = {34s, trash, not relevant to me}
}

@article{yue_detecting_2019,
	title = {Detecting {LDoS} attack bursts based on queue distribution},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5097},
	abstract = {Low-rate denial of service (LDoS) attacks exploit the congestion control mechanism to degrade the network quality of service. As a classic active queue management algorithm, random early detection (RED) algorithm is widely used to avoid network congestion. However, RED is vulnerable to LDoS attacks. LDoS attacks with well-configured attack parameters force RED queue to fluctuate severely, thereby throttling transmission control protocol (TCP) senders’ sending rate. A feedback control model is proposed to describe the process of the congestion control, by which the congestion window and queue behaviours are analysed combined. After that, a two-dimensional queue distribution model composed of the instantaneous queue and the average queue is designed to extract the attack feature. Moreover then, a combination of a simple distance-based approach and an adaptive threshold algorithm is proposed to detect every LDoS attack burst. Test results of network simulator (NS)-2 simulation and test-bed experiments indicate that the proposed detection strategy can almost completely detect LDoS attack bursts and is especially robust to legitimate short bursts.},
	language = {English},
	number = {3},
	journal = {IET Information Security},
	author = {Yue, Meng and Wu, Zhijun and Wang, Jingjie},
	month = may,
	year = {2019},
	keywords = {attack feature, classic active queue management algorithm, congestion control mechanism, feedback control model, LDoS attack burst, low-rate denial of service attacks, network congestion, queue behaviours, random early detection, RED queue, TCP senders, two-dimensional queue distribution model},
	pages = {285--292(7)},
	annote = {1m45s, trash, network DOS not relevant to me}
}

@article{nia_detecting_2019,
	title = {Detecting new generations of threats using attribute-based attack graphs},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5409},
	abstract = {In recent years, the increase in cyber threats has raised many concerns about security and privacy in the digital world. However, new attack methods are often limited to a few core techniques. Here, in order to detect new threat patterns, the authors use an attack graph structure to model unprecedented network traffic. This graph for the unknown attack is matched to a pre-known threat database, which contains attack graphs related to each known threat. The main challenge is to associate unknown traffics to a family of known threats. For this, the authors utilise random walks and pattern theorem. The authors utilise the pattern theorem and apply it to a set of proposed algorithms for detecting new generations of malicious traffics. Under the assumption of having a proper threat database, the authors argue that for each unknown threat, which belongs to a family of threats, it is possible to find at least one matching pattern with high matching rate and sensitivity.},
	language = {English},
	number = {4},
	journal = {IET Information Security},
	author = {Nia, Mehran Alidoost and Bahrak, Behnam and Kargahi, Mehdi and Fabian, Benjamin},
	month = jul,
	year = {2019},
	keywords = {attack graph structure, attack methods, attribute-based attack graphs, core techniques, cyber threats, digital world, generations, malicious traffics, matching pattern, pre-known threat database, privacy, proper threat database, security, threat patterns, unknown attack, unknown threat, unknown traffics, unprecedented network traffic},
	pages = {293--303(10)},
	annote = {1m1s, trash, not cutting edge, threat detection}
}

@article{ouladj_chosen_2019,
	title = {Chosen message strategy to improve the correlation power analysis},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5103},
	abstract = {Nowadays cryptographic circuits are subject to attacks that no longer focus on the algorithm but on its physical implementation. Attacks exploiting information leaked by the hardware implementation are called side-channel attacks (SCA). In particular, the popular correlation power analysis (CPA) is known by its effectiveness. This paper presents a new method for an original optimisation of the CPA to recover secret keys with less power consumption traces than what is expected from the standard CPA. This improvement is done by choosing appropriate plaintexts, both non-adaptively and adaptively. A mathematical proof of the proposed procedure is provided for any cryptographic device with any known leakage model. The proposed technique is tested on the advanced encryption system (AES) S-box input (resp. output) implemented in an ATMega 163 smartcard, with hamming weight leakage model.},
	language = {English},
	number = {4},
	journal = {IET Information Security},
	author = {Ouladj, Maamar and Guillot, Phillipe and Mokrane, Farid},
	month = jul,
	year = {2019},
	keywords = {advanced encryption system S-box input, appropriate plaintexts, ATMega 163 smartcard, chosen message strategy, correlation power analysis, CPA, cryptographic circuits, cryptographic device, hamming weight leakage model, hardware implementation, original optimisation, physical implementation, power consumption traces, secret keys, side-channel attacks},
	pages = {304--310(6)},
	annote = {37s, trash, this was almost a maybe, it's encryption, but related to side channel attacks which are more interesting}
}

@article{bag_priveto:_2019,
	title = {{PriVeto}: a fully private two-round veto protocol},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5115},
	abstract = {In 2006, Hao and Zieliński presented a two-round veto protocol named anonymous veto network (AV-net), which is exceptionally efficient in terms of the number of rounds, computation and bandwidth usage. However, AV-net has two generic issues: (i) a participant who has submitted a veto can find out whether she is the only one who vetoed; (ii) the last participant who submits her input can pre-compute the Boolean-OR result before submission, and may amend her input based on that knowledge. These two issues generally apply to any multi-round veto protocol where participants commit their input in the last round. In this study, the authors propose a novel solution to address both issues within two rounds, which are the best possible round efficiency for a veto protocol. Their new private veto protocol, called PriVeto, has similar system complexities to AV-net, but it binds participants to their inputs in the very first round, eliminating the possibility of runtime changes to any of the inputs. At the end of the protocol, participants are strictly limited to learning nothing more than the output of the Boolean-OR function and their own inputs.},
	language = {English},
	number = {4},
	journal = {IET Information Security},
	author = {Bag, Samiran and Azad, Muhammad Ajmal and Hao, Feng},
	month = jul,
	year = {2019},
	keywords = {anonymous veto network, AV-net, private veto protocol, PriVeto, two-round veto protocol},
	pages = {311--320(9)},
	annote = {47s, trash, unclear even what the concept of this paper is}
}

@article{ruth_secure_2019,
	title = {Secure data storage and intrusion detection in the cloud using {MANN} and dual encryption through various attacks},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5295},
	abstract = {Nowadays, it is very important to maintain a high level security to ensure safe and trusted communication of information between various organisations. But secured data communication over the Internet and any other network is always under threat of intrusions and misuses. So intrusion detection system (IDS) has become a needful component in terms of computer and network security. In this research, the authors have intended to propose an effective method for text data based IDS and secure data storage. In the proposed preprocessing steps, the input text document is preprocessed and then change to the desired format. Next the resultant output is fed to the IDS. Here user text data is checked; whether the given data is normal or intrusive based on a modified artificial neural network (MANN). Here traditional neural network is modified by means of modified particle swarm optimisation. The final process of the authors’ proposed method is to encrypt the file using dual encryption algorithms (RSA and AES). To improve the storage security of the proposed method, steganography techniques are utilised after the dual encryption. Their proposed system is implemented with the help of Cloud simulator in the working platform Java.},
	language = {English},
	number = {4},
	journal = {IET Information Security},
	author = {Ruth, J. Anitha and Sirmathi, H. and Meenakshi, A.},
	month = jul,
	year = {2019},
	keywords = {AES, cloud simulator, computer security, data communication, dual encryption algorithms, IDS, input text document, Internet, intrusion detection system, Java, MANN, modified artificial neural network, network security, particle swarm optimisation, RSA, secure data storage, steganography techniques, storage security, user text data},
	pages = {321--329(8)},
	annote = {36s, trash, cloud encryption}
}

@article{zhang_certifying_2019,
	title = {Certifying multi-power {RSA}},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5178},
	abstract = {In this study, the authors present two rigorous algorithms to certify the trapdoor permutation property of the RSA function RS A N , e ( x ) := x e mod N , where N = p r q is a multi-power RSA modulus with unknown factorisation and r is a known positive integer. Their work gives effective certification for a prime exponent e when e ≥ 2 N ( gcd ( r , e − 1 ) ) / ( r + 1 ) 2 + ϵ and for a composite integer e = e 1 s 1 e 2 s 2 ⋯ e u s u when e i ≥ 2 N ( gcd ( r , e i − 1 ) ) / ( r + 1 ) 2 + ϵ for i = 1 , … , u , where e i is a known prime, s i is a positive integer, and ϵ \&gt; 0 is some small enough constant. The algorithms apply Coppersmith\&apos;s method for solving univariate modular polynomial equations and run in time O ( ϵ − 7 C log 2 N ) , where C ≤ u r 2 is a constant number.},
	language = {English},
	number = {4},
	journal = {IET Information Security},
	author = {Zhang, Xiaona and Wang, Li-Ping and Xu, Jun},
	month = jul,
	year = {2019},
	keywords = {certifying multipower RSA, multipower RSA modulus, positive integer, trapdoor permutation property},
	pages = {330--335(5)},
	annote = {9s, trash, encryption}
}

@article{noroozi_public_2019,
	title = {Public key authenticated encryption with keyword search: revisited},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5315},
	abstract = {In 2017, the notion of public key authenticated encryption with keyword search (PAEKS) and its security model was defined by Huang and Li. Their main motivation was providing security against inside keyword guessing attacks (KGA). They also proposed a concrete PAEKS scheme secure in their proposed model. In this study, the authors first show that their security model has an important drawback and therefore, cannot handle multi-user settings. As such settings are a necessity in the public-key environment, it is vital to improving the model to capture multiple users. This is what they do in the first part of this study. Then, they consider Huang and Li\&apos;s PAEKS scheme and prove that it is not secure against inside (and even outside) KGA. Finally, they propose a modified scheme to fix the problem without any additional communication or computation costs. They further prove that the new scheme is secure in the improved model.},
	language = {English},
	number = {4},
	journal = {IET Information Security},
	author = {Noroozi, Mahnaz and Eslami, Ziba},
	month = jul,
	year = {2019},
	keywords = {computation costs, concrete PAEKS scheme, keyword guessing attacks, KGA, Li, multiuser settings, public key authenticated encryption with keyword search, public-key environment, security model},
	pages = {336--342(6)},
	annote = {37s, trash, public key encryption}
}

@article{dehkordi_how_2019,
	title = {How to construct a verifiable multi-secret sharing scheme based on graded encoding schemes},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5306},
	abstract = {In a verifiable multi-secret sharing scheme, a dealer distributes multiple secrets between a group of participants and also additional information is given that allows each participant to check whether his share is valid. In this study, the authors present a novel verifiable multi-secret sharing (VMSS) scheme with general access structure using monotone span programs, which its security is based on graded encoding schemes. More precisely, they reduce the hardness of graded decision-Diffie–Hellman problem to the computational security of the authors’ scheme in the standard model. To the best of the authors’ knowledge, this is the first study to present a VMSS scheme based on graded encoding schemes.},
	language = {English},
	number = {4},
	journal = {IET Information Security},
	author = {Dehkordi, Massoud Hadian and Oraei, Hossein},
	month = jul,
	year = {2019},
	keywords = {computational security, general access structure, graded decision-Diffie–Hellman problem, graded encoding schemes, monotone span programs, verifiable multisecret sharing scheme, VMSS scheme},
	pages = {343--351(8)},
	annote = {49s, trash, not interested in multi secret sharing schemes}
}

@article{vartouni_leveraging_2019,
	title = {Leveraging deep neural networks for anomaly-based web application firewall},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5404},
	abstract = {Web applications are the most common platforms for the exchange of information and services on the Internet. With the launch of web 2.0, information has flourished through social networking and business online. Therefore, websites are often attacked directly. As a result, the industry has paid more attention to the security of web applications in addition to security under computer networks. Intelligent systems based on machine learning have demonstrated excellent result on tasks such as anomaly detection in web requests. However, current methods based on traditional models cannot extract high-level features from huge data. In this study, the authors proposed methods based on deep-neural-network and parallel-feature-fusion that features engineering as an integral part of them and plays the most important role in their performance. The proposed methods use stacked autoencoder and deep belief network as feature learning methods, in which only normal data is used in the classification of training phase, then, one-class SVM, isolation forest, and elliptic envelope are applied as classifiers. The authors compared the proposed model with different strategies on CSIC 2010 and ECML/PKDD 2007 datasets. Results show that deep model and feature fusion model demonstrated as hierarchical feature learning which had better performance in terms of accuracy and generalisation in a reasonable time.},
	language = {English},
	number = {4},
	journal = {IET Information Security},
	author = {Vartouni, Ali Moradi and Teshnehlab, Mohammad and Kashi, Saeed Sedighian},
	month = jul,
	year = {2019},
	keywords = {anomaly detection, anomaly-based web application firewall, business online, common platforms, computer networks, current methods, deep belief network, deep model, deep neural networks, deep-neural-network, excellent result, feature learning methods, features engineering, hierarchical feature learning, high-level features, huge data, intelligent systems, machine learning, parallel-feature-fusion, social networking, web applications, web requests},
	pages = {352--361(9)},
	annote = {1m40s, trash, poorly written, unclear concept}
}

@article{pena_non-quantum_2019,
	title = {Non-quantum cryptanalysis of the noisy version of {Aaronson}–{Christiano}\&apos;s quantum money scheme},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5307},
	abstract = {At STOC 2012, Aaronson and Christiano proposed a noisy and a noiseless version of the first public-key quantum money scheme endowed with a security proof. This paper addresses the so-called noisy hidden subspaces problem, on which the noisy version of their scheme is based. The first contribution of this work is a non-quantum cryptanalysis of the above-mentioned noisy quantum money scheme extended to prime fields F , with {\textbar} F {\textbar} ≠ 2 , that runs in randomised polynomial time. This finding is supported with experimental results showing that, in practice, the algorithm presented is efficient and succeeds with overwhelming probability. The second contribution is a non-quantum randomised polynomial-time cryptanalysis of the noisy quantum money scheme over F 2 succeeding with a certain probability for values of the noise lying within a certain range. This result disproves a conjecture made by Aaronson and Christiano about the non-existence of an algorithm that solves the noisy hidden subspaces problem over F 2 and succeeds with such probability.},
	language = {English},
	number = {4},
	journal = {IET Information Security},
	author = {Pena, Marta Conde and Díaz, Raul Durán and Faugère, Jean-Charles and Encinas, Luis Hernández and Perret, Ludovic},
	month = jul,
	year = {2019},
	keywords = {Aaronson-Christiano\&apos, noiseless version, noisy hidden subspaces problem, noisy quantum money scheme, nonquantum cryptanalysis, polynomial-time cryptanalysis, public-key quantum money scheme, randomised polynomial time, s quantum money scheme, STOC 2012},
	pages = {362--366(4)},
	annote = {44s, trash, encryption}
}

@article{tang_dynamic_2019,
	title = {Dynamic {API} call sequence visualisation for malware classification},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5268},
	abstract = {Due to the development of automated malware generation and obfuscation, traditional malware detection methods based on signature matching have limited effectiveness. Thus, a novel approach using visualisation and deep learning technology can play an important role in malware detection and classification. In this study, the authors extract sequences of API calls using dynamic analysis and then use colour mapping rules to create feature images representing malware behaviour. Finally, they train a convolutional neural network to classify different feature images with 9 malware families, and 1000 variants in each family. Experimental results show the effectiveness of the authors’ method. The classification TPR, precision, recall and F1 are all \&gt;99\%, while the FPR is \&lt;0.1\%.},
	language = {English},
	number = {4},
	journal = {IET Information Security},
	author = {Tang, Mingdong and Qian, Quan},
	month = jul,
	year = {2019},
	keywords = {9 malware families, authors, deep learning technology, different feature images, dynamic analysis, dynamic API call sequence visualisation, malware behaviour, malware classification, recall, signature matching, traditional malware detection methods},
	pages = {367--377(10)},
	annote = {1m34s, scan, dynamic malware classification looks interesting},
	annote = {scan notes: The effectiveness of signature based malware is limited. Using dynamic analysis and a learning network could be able to identify more malware.}
}

@article{saha_dinamite:_2019,
	title = {Dinamite: internal differential match-in-the-end attack on eight-round {PAEQ}},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5033},
	abstract = {The authors explore a cryptanalysis strategy which seems to be particularly applicable to parallelisable ciphers where the key forms a part of the internal state. The proposed technique combines internal differentials with guess and determine analysis to come up with what is referred to as the match-in-the-end attack. The notion of difference here deviates from the classical differential where the difference is controllable via the plaintext/ciphertext. Here, they exploit the Hamming distance between parallel branches to devise the differential trail. They apply the strategy on full eight (out of 20) rounds of parallelisable authenticated cipher [parallelisable AE based on quadrupled AES (PAEQ)] to devise key recovery attacks with practical time complexities. They first show an initial attack on paeq-64/80/128 and then devise improvements which give us the best key-recovery attacks with time complexities of 2 33 , 2 48 , and 2 64 , respectively. While the best reported attacks on eight-round paeq-64/80/128 have a data complexity of 2 89 blocks, the result improves their time complexities by factors of 2 , 2 18 , and 2 34 , while preserving the data complexity. Finally, they present a nonce-based differential attack which works on paeq-128-t with 2 64 time complexity but uses just two single block known plaintexts making it the most practical attack on any round-reduced PAEQ variant reported so far.},
	language = {English},
	number = {4},
	journal = {IET Information Security},
	author = {Saha, Dhiman and Kakarla, Sourya and Chowdhury, Dipanwita Roy},
	month = jul,
	year = {2019},
	keywords = {classical differential, cryptanalysis strategy, data complexity, differential trail, Dinamite, eight-round PAEQ, internal differential match-in-the-end attack, internal differentials, key recovery attacks, key-recovery attacks, nonce-based differential attack, PAEQ variant, parallelisable authenticated cipher, parallelisable ciphers, plaintext-ciphertext, time complexities, time complexity},
	pages = {378--388(10)},
	annote = {54s, trash, crypto}
}

@article{zhao_encrypted_2019,
	title = {Encrypted secure polar coding scheme for general two-way wiretap channel},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5472},
	abstract = {The authors consider the problems of key exchange for one-time pad along with the problem of rate sacrifice for secure polar coding over the two-way wiretap channel under the strong security criterion. Based on existing techniques, they present a new hash chaining structure to solve the good bits sacrificing problem for achieving the strong security and constructed encryption embedded secure polar coding scheme for two-way wiretap channel. To implement a one-time pad without any key pre-sharing, they design a secure and reliable transmission for both key and ciphertext coupling with the cooperative jamming strategy, which can also increase the secrecy rate for communication. As proved, extended upper bounds for both achievable secrecy rate pair and effective secrecy rate pair can be achieved under the strong security and reliability criterions.},
	language = {English},
	number = {4},
	journal = {IET Information Security},
	author = {Zhao, Yizhi and Xu, Shiwei and Chi, Hongmei},
	month = jul,
	year = {2019},
	keywords = {achievable secrecy rate pair, ciphertext coupling, constructed encryption, key coupling, key exchange, key pre-sharing, one-time pad, rate sacrifice, reliable transmission, secure polar coding scheme, secure transmission, strong security criterion, two-way wiretap channel},
	pages = {393--403(10)},
	annote = {30s, trash, encryption}
}

@article{baldi_security_2019,
	title = {Security of generalised {Reed}–{Solomon} code-based cryptosystems},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5207},
	abstract = {In this study, the authors elaborate on a recently proposed variant of the public-key McEliece and Niederreiter cryptosystems using generalised Reed–Solomon (GRS) codes as private codes. The use of these codes brings known advantages in terms of public key size, but particular care is needed in the choice of parameters not to endanger the system security. In fact, the considered system exploits a strong disguising technique of the private code within the public code. However, it has recently been pointed out that some new attacks exist which may threaten some instances of such a system, therefore the choice of parameters needs to consider some further constraints compared to the original version. After outlining these constraints, the authors propose a new modification of the system achieving greater flexibility in the parameter choice. Moreover, the new system exhibits a lower complexity than the original GRS code-based system. Its very competitive features such as key size and encryption rate are highlighted with respect to classic systems.},
	language = {English},
	number = {4},
	journal = {IET Information Security},
	author = {Baldi, Marco and Chiaraluce, Franco and Rosenthal, Joachim and Santini, Paolo and Schipani, Davide},
	month = jul,
	year = {2019},
	keywords = {classical systems, considered system, encryption rate, generalised Reed–Solomon code-based cryptosystems, generalised Reed–Solomon codes, original GRS code-based system, parameter choice, particular care, private code, public code, public key size, recently proposed variant, strong disguising technique, system exhibits, system security},
	pages = {404--410(6)},
	annote = {14s, trash, proposed variant of crypto algorithm}
}

@article{jiao_improved_2019,
	title = {Improved guess-and-determine attack on {TRIVIUM}},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5357},
	abstract = {TRIVIUM is a stream cipher of the finalists by eSTREAM project and has been accepted as ISO standard. Although the design has a simple structure, no attack on its full cipher has been found yet. In this study, based on Maximov and Biryukov\&apos;s attack, the authors present an improved guess-and-determine attack on TRIVIUM. Analysis details are provided corresponding to TRIVIUM specifications for better comprehension, and errors that may lead to higher attack complexity in the original attack are pointed and corrected. They further bring in some techniques like backward-clock equation collection, quadratic equations, linear transformation to improve the attack. In addition, they integrate with time-memory-data tradeoffs from the framework, based on the analysis of the coefficient matrices form of derived linear equation systems on the internal state. In this way, better use of the imposed quadratic conditions can be made, which leads to reduced attack complexity by filtering out the impossible keystreams before solving the equation systems. Their attack offers more parameter selections, and gives several borderline results compared with the key exhaustive search. The new attack behaves better in the original case. It also verifies the necessity of data requirement imposed on TRIVIUM, which is questioned in TRIVIUM specifications.},
	language = {English},
	number = {5},
	journal = {IET Information Security},
	author = {Jiao, Lin and Hao, Yonglin and Li, Yongqiang},
	month = sep,
	year = {2019},
	keywords = {backward-clock equation collection, Biryukov attack, cipher version, guess-and-determine attack, higher attack complexity, linear equation systems, original attack, quadratic equations, reduced attack complexity, stream cipher, Trivium specifications},
	pages = {411--419(8)},
	annote = {45s, trash, crypto attack}
}

@article{wang_esr_2019,
	title = {{ESR} analysis over {ST}-{MRC} multi-input multi-output {Nakagami} fading channels},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5185},
	abstract = {Different from conventional key-based cryptography schemes, physical-layer security (PLS) techniques have drawn much attention recently to realise unconditional security from the information theory perspective. As an important performance metric in PLS, the ergodic secrecy rate (ESR) for a multi-input multi-output wireless communication network over a Nakagami fading channel is analysed. The network is consisted of a multi-antenna transmitter (Alice), a multi-antenna legitimate receiver (Bob), and a multi-antenna eavesdropper (Eve). By using the selective transmission (ST) at Alice and the maximum ratio combining (MRC) at Bob and Eve, an exact expression of the ESR is derived. However, due to the infinite summation, it is very hard to evaluate the ESR performance. To reduce computational complexity and obtain more insights, a lower bound of the ESR is then obtained, which is in a closed form. As special cases, the lower bounds of the ESR for the signal-antenna scenario and Rayleigh fading channel are also obtained, respectively. Numerical results show that the derived expressions of the ESR and its lower bound are very accurate to evaluate system performance.},
	language = {English},
	number = {5},
	journal = {IET Information Security},
	author = {Wang, Jin-Yuan and Lin, Sheng-Hong and Cai, Wei and Dai, Jianxin},
	month = sep,
	year = {2019},
	keywords = {computational complexity, ergodic secrecy rate, ESR analysis, ESR performance, infinite summation, information theory perspective, key-based cryptography schemes, lower bound, maximum ratio combining, multiantenna eavesdropper, multiantenna legitimate receiver, multiantenna transmitter, multiinput multioutput wireless communication network, performance metric, physical-layer security techniques, PLS techniques, selective transmission, signal-antenna scenario, ST-MRC multiinput multioutput Nakagami fading channels, system performance evaluation, unconditional security},
	pages = {420--425(5)},
	annote = {34s, trash, encryption}
}

@article{zhou_identity-based_2019,
	title = {Identity-based encryption resilient to continuous key leakage},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5203},
	abstract = {Leakage of private information has become a threat to the security of computing systems. It has become a common security requirement that a cryptography scheme should withstand various leakage attacks, even the continuous leakage attacks. However, in the current constructions on the (continuous) leakage-resilient identity-based encryption (CLR-IBE) scheme, the leakage parameter is a fixed value. Aiming to solve these problems, in this study, the authors show how to construct the CLR-IBE scheme, and the adaptive chosen-ciphertext attacks security of proposed construction can be proved in the standard model. To further improve the practicability of CLR-IBE scheme, they design an improved IBE scheme with continuous leakage amplified property, and the leakage parameter has an arbitrary length.},
	language = {English},
	number = {5},
	journal = {IET Information Security},
	author = {Zhou, Yanwei and Yang, Bo and Mu, Yi and Wang, Tao and Wang, Xin},
	month = sep,
	year = {2019},
	keywords = {adaptive CCA security, bounded leakage attacks, chosen-ciphertext attacks security, chosen-plaintext attacks security, CLR-IBE scheme, continuous key leakage, continuous leakage amplified property, continuous leakage attacks, continuous leakage setting, cryptography scheme, identity-based encryption schemes, leakage parameter, leakage requirements, leakage-resilient IBE scheme, permitted leakage, private information, security requirement, selective identity model},
	pages = {426--434(8)},
	annote = {1m11s, trash, crypto}
}

@article{zuzcak_causal_2019,
	title = {Causal analysis of attacks against honeypots based on properties of countries},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5141},
	abstract = {This study studies the influence of country attributes on the number of secure shell attacks originating from it detected by the author\&apos;s honeynet. Four statistical models are described, based on three sources of data from various countries. The studied attributes of the countries can be broadly divided into demographic, technological, and economic, with each source providing a slightly different set of attributes. Statistical methods such as partial least-squares path modelling are used, clustering countries by their assessed similarity. The population size has the greatest effect on the number of attacks, as expected, though it has to be noted that developing countries did not provide relevant data to the sources used and thus were not included. The following influential attributes were technical such as the access to information and communication technologies (ICT), and the use of ICT, with the economic influence being notable only in rather small countries. The Netherlands was an interesting anomaly, being clustered alongside large countries, even though its country attributes were very much like those of its neighbours.},
	language = {English},
	number = {5},
	journal = {IET Information Security},
	author = {Zuzčák, Matej and Bujok, Petr},
	month = sep,
	year = {2019},
	keywords = {author honeynet, country attributes, developing countries, influential attributes, secure shell attacks, statistical models},
	pages = {435--447(12)},
	annote = {1m3s, scan, demograph analysis of attacks by country seems interesting},
	annote = {scan notes: use a honeypot to identify demographic data about attackers related to the country of origin. May be helpful for performing risk analysis on users attempting to connect to your network}
}

@article{arabnezhad-khanoki_s-boxes_2019,
	title = {S-boxes representation and efficiency of algebraic attack},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5201},
	abstract = {Algebraic analysis of block ciphers aims at finding the secret key by solving a collection of polynomial equations that describe the internal structure of a cipher for chosen observations of plaintext/ciphertext pairs. Although algebraic attacks are addressed for cryptanalysis of block and stream ciphers, there is a lack of understanding of the impact of algebraic representation of the cipher on efficiency of solving the resulting collection of equations. The study investigates some different S-box representations and their effect on complexity of algebraic attacks. In particular, the authors observe that a S-box representation defined in the work as forward–backward (FWBW) leads to a collection of equations that can be solved efficiently. They show that the SR(10,2,1,4) cipher can be broken with algebraic cryptanalysis using standard algebra software Singular and FGb. This is the best result achieved so far. The effect of description of S-boxes for some light-weight block ciphers is investigated. A by-product of this result is that some improvements have been achieved on the algebraic cryptanalysis of LBlock, PRESENT and MIBS light-weight block ciphers. The authors’ study and experiments confirm a counter-intuitive conclusion that algebraic attacks work best for the FWBW S-box representation. This contradicts a common belief that algebraic attacks are more efficient with quadratic S-box representation.},
	language = {English},
	number = {5},
	journal = {IET Information Security},
	author = {Arabnezhad-Khanoki, Hossein and Sadeghiyan, Babak and Pieprzyk, Josef},
	month = sep,
	year = {2019},
	keywords = {algebraic analysis, algebraic attack, algebraic attacks, algebraic cryptanalysis, algebraic representation, ciphertext pair, forward-backward, FWBW S-box representation, LBlock light-weight block cipher, MIBS light-weight block cipher, plaintext pair, PRESENT light-weight block cipher, quadratic S-box representation, resulting collection-of-equations, S-boxes representation, stream ciphers},
	pages = {448--458(10)},
	annote = {18s, trash, crypto}
}

@article{rastegari_multi-designated_2019,
	title = {Multi-designated verifiers signature schemes with threshold verifiability: generic pattern and a concrete scheme in the standard model},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5063},
	abstract = {In a designated verifier signature (DVS) scheme, the validity of the signature can only be checked by a designated entity chosen by the signer. Furthermore, the designated entity cannot convince a third party that the signature is generated by the signer. A multi-designated verifiers signature (MDVS) scheme is an extension of a DVS which includes multiple designated verifiers. To the best of the authors’ knowledge, there are two existing patterns for an MDVS scheme. In the first pattern, every verifier of the set of designated verifiers can check the validity of the signature independently. In the second pattern, the cooperation of all designated verifiers is required for checking the validity of the signature. In this study, the authors propose a generic new pattern for an MDVS scheme in which a threshold number of the set of designated verifiers can check the validity of the signature. They also present a concrete MDVS scheme with threshold verifiability in the standard model. Moreover, they compare their scheme with other existing MDVS schemes. Finally, they briefly explain scenarios in which the proposed pattern can be applicable.},
	language = {English},
	number = {5},
	journal = {IET Information Security},
	author = {Rastegari, Parvin and Dakhilalian, Mohammad and Berenjkoub, Mehdi and Susilo, Willy},
	month = sep,
	year = {2019},
	keywords = {concrete MDVS scheme, designated entity, generic pattern, multidesignated verifiers signature scheme, standard model, threshold verifiability},
	pages = {459--468(9)},
	annote = {20s, trash, not relevant}
}

@article{yan_new_2019,
	title = {New zero-sum distinguishers on full 24-round {Keccak}-f using the division property},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5263},
	abstract = {The authors analyse the security of Keccak (the winner in SHA-3 competition) by focusing on the zero-sum distinguishers of its underlying permutation (named Keccak-f). The authors’ analyses are developed by using the division property, a generalised integral property that was initially used in the integral cryptanalysis of symmetric-key algorithms. Following the work pioneered by Todo at CRYPTO 2015, they first formalise and prove a more delicate propagation rule of the division property under the assumption that the S-box\&apos;s specification is known to attackers. Then, they apply this rule to the inverse S-box in Keccak-f with a further study on properties of its algebraic degree. They find that the rate of decline in the division property is gentler than that of a randomly chosen S-box. Meanwhile, they get the same results for the S-box in Ascon permutation. Thanks to this vulnerable property, they can improve the higher-order differential characteristics against the inverse of Keccak-f in terms of the required number of chosen plaintexts. As an application, they give new zero-sum distinguishers on full 24-round Keccak-f of size 2 1573 . To the authors’ knowledge, this is currently the best zero-sum distinguishers of full-round Keccak-f permutation. Incidentally, they give the corresponding results for 12-round Ascon permutation.},
	language = {English},
	number = {5},
	journal = {IET Information Security},
	author = {Yan, Hailun and Lai, Xuejia and Wang, Lei and Yu, Yu and Xing, Yiran},
	month = sep,
	year = {2019},
	keywords = {algebraic degree, Ascon permutation, division property, generalised integral property, higher-order differential characteristics, integral cryptanalysis, KECCAK-f, propagation rule, S-box specification, symmetric-key algorithms, vulnerable property, zero-sum distinguishers},
	pages = {469--478(9)},
	annote = {14s, trash, crypto}
}

@article{li_new_2019,
	title = {New method to describe the differential distribution table for large {S}-boxes in {MILP} and its application},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5284},
	abstract = {Based on the method of the H-representation of the convex hull, the linear inequalities of all possible differential patterns of 4-bit S-boxes in the mix integer linear programming (MILP) model can be generated easily by the SAGE software. Whereas this method cannot be apply to 8-bit S-boxes. In this study, the authors propose a new method to obtain the inequalities for large S-boxes with the coefficients belonging to integer. The relationship between the coefficients of the inequalities and the corresponding excluded impossible differential patterns is obtained. As a result, the number of inequalities can be lower than 4000 for the AES S-box. Then, the new method for finding the best probability of the differential characteristics of 4–15 rounds SM4 in the single-key setting is presented. Especially, the authors found that the 15-round SM4 exists four differential characteristics with 12 active S-boxes. The exact lower bound of the number of differentially active S-boxes of the 16-round SM4 is 15. The authors also found eight differential characteristics of the 19-round SM4 with the probability 2 − 124 .},
	language = {English},
	number = {5},
	journal = {IET Information Security},
	author = {Li, Ling-Chen and Wu, Wen-Ling and Zhang, Lei and Zheng, Ya-Fei},
	month = sep,
	year = {2019},
	keywords = {AES S-box, convex hull, differential distribution table, differential patterns, differentially active S-boxes, H-representation, linear inequalities, MILP, mix integer linear programming model, SAGE software},
	pages = {479--485(6)},
	annote = {24s, trash, crypto}
}

@article{noferesti_inline_2019,
	title = {Inline high-bandwidth network analysis using a robust stream clustering algorithm},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5287},
	abstract = {High-bandwidth network analysis is challenging, resource consuming, and inaccurate due to the high volume, velocity, and variety characteristics of the network traffic. The infinite stream of incoming traffic forms a dynamic environment with unexpected changes, which requires analysing approaches to satisfy the high-bandwidth network processing challenges such as incremental learning, inline processing, and outlier handling. This study proposes an inline high-bandwidth network stream clustering algorithm designed to incrementally mine large amounts of continuously transmitting network traffic when some outliers can be dropped before determining the network traffic behaviour. Maintaining extended-meta-events as abstracting data structures over a sliding window, enriches the algorithm to address the high-bandwidth network processing challenges. Evaluating the algorithm indicates its robustness, efficiency, and accuracy in analysing high-bandwidth networks.},
	language = {English},
	number = {5},
	journal = {IET Information Security},
	author = {Noferesti, Morteza and Jalili, Rasool},
	month = sep,
	year = {2019},
	keywords = {abstracting data structures, continuously transmitting network traffic, high-bandwidth network analysis, inline high-bandwidth network stream clustering algorithm, network traffic behaviour, robust stream clustering algorithm, sliding window},
	pages = {486--495(9)},
	annote = {56s, scan, high volume network traffic analysis}
}

@article{nunez_escrowed_2019,
	title = {Escrowed decryption protocols for lawful interception of encrypted data},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5082},
	abstract = {Escrowed decryption schemes (EDSs) are public-key encryption schemes with an escrowed decryption functionality that allows authorities to decrypt encrypted messages under investigation, following a protocol that involves a set of trusted entities called ‘custodians’; only if custodians collaborate, the requesting authority is capable of decrypting encrypted data. This type of cryptosystem represents an interesting trade-off to privacy versus surveillance dichotomy. In this study, the authors propose two EDSs where they use proxy re-encryption to build the escrowed decryption capability, so that custodians re-encrypt ciphertexts, in a distributed way, upon request from an escrow authority, and the re-encrypted ciphertexts can be opened only by the escrow authority. Their first scheme, called EDS, follows an all-or-nothing approach, which means that escrow decryption only works when all custodians collaborate. Their second scheme, called threshold EDS, supports a threshold number of custodians for the escrow decryption operation. They propose definitions of semantic security with respect to the authorities, custodians and external entities, and prove the security of their schemes, under standard pairing-based hardness assumptions. Finally, they present a theoretical and experimental analysis of the performance of both schemes, which show that they are applicable to real-world scenarios.},
	language = {English},
	number = {5},
	journal = {IET Information Security},
	author = {Nuñez, David and Agudo, Isaac and Lopez, Javier},
	month = sep,
	year = {2019},
	keywords = {custodian collaboration, EDS, encrypted data, encrypted messages, escrow authority, escrow decryption operation, escrowed decryption functionality, escrowed decryption protocols, escrowed decryption schemes, lawful interception, privacy, proxy re-encryption, public-key encryption schemes, re-encrypted ciphertexts, requesting authority, surveillance, trusted entities},
	pages = {498--507(9)},
	annote = {42s, trash, decryption}
}

@article{bagherpour_sigma_2019,
	title = {Sigma protocol for faster proof of simultaneous homomorphism relations},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5167},
	abstract = {The Σ -protocols for homomorphism relations are one of the cryptographic protocols which are used to prove knowledge of homomorphism relations. The Schnorr protocol is one of the most famous Σ -protocols used for proving knowledge of discrete logarithm (DL) relation in which the verifier essentially performs one double-exponentiation (i.e. a group computation of the form axby ). A direct application of the Schnorr protocol for proving simultaneous knowledge of n DLs with a common base leads to a Σ -protocol in which the verifier performs n double-exponentiations. In this study, the authors propose another Σ -protocol for homomorphism relations. The proposed Σ -protocol has fast verification when is used to prove the simultaneous homomorphism relations with a common homomorphism. Also, when the DL instantiation (DL-instantiation) of the proposed Σ -protocol is used to prove simultaneous knowledge of n DLs with a common base, it leads to a Σ -protocol in which the verifier performs n+1 single-exponentiations.},
	language = {English},
	number = {5},
	journal = {IET Information Security},
	author = {Bagherpour, Bagher and Zaghian, Ali and Sajadieh, Mahdi},
	month = sep,
	year = {2019},
	keywords = {cryptographic protocols, discrete logarithm relation, DL instantiation, DL relation, n+1 single-exponentiations, Schnorr protocol, sigma protocol, simultaneous homomorphism relations, Σ-protocols},
	pages = {508--514(6)},
	annote = {31s trash, crypto}
}

@article{zhang_build_2019,
	title = {Build a trusted storage system on a mobile phone},
	volume = {13},
	copyright = {© The Institution of Engineering and Technology},
	issn = {1751-8709},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-ifs.2018.5031},
	abstract = {The authors introduce their design, implementation and formally verification of a Trusted Execution Environment (TEE)-based trusted storage system (TSS) in mobile devices, which conforms to GlobalPlatform specifications. The authors’ TSS provides not only authenticating the integrity and freshness of data but also many security storage operation properties like atomicity operations of a persistent object. To improve data store efficient when a big persistent object is read or written, a new mechanism that dynamic allocate continuous memory in REE\&apos;s kernel memory space and map the address to the TEE through a communication pipe is proposed. This method can reduce switching times, allocating memory times and copy memory overloads between two worlds. A formal method is used in their design and development to guarantee the correctness and security of TSS. They consider the functional correctness mainly in this study, and use traditional formal verification tool – VCC verify the functional correctness of TSS. Their evaluation demonstrates its advantage compared to existing systems in addition.},
	language = {English},
	number = {2},
	journal = {IET Information Security},
	author = {Zhang, Qiang and Qiao, JianZhong and Meng, QingYang},
	month = mar,
	year = {2019},
	keywords = {atomicity operations, data integrity, formal method, functional correctness, GlobalPlatform specifications, memory overloads, memory times allocation, mobile devices, mobile phone, REE\&apos, s kernel memory space, security storage operation properties, TEE, traditional formal verification tool, Trusted Execution Environment-based trusted storage system, TSS},
	pages = {157--166(9)},
	annote = {49s, scan, trusted mobile storage is relevant meaningful issue
scan notes: Secure mobile storage is a relevant problem, but there are many solutions already in place. This paper proposed and easier formal verification process, but was more of a survey paper}
}